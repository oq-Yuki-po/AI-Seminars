# E 資格まとめ {ignore=true}

## 目次 {ignore=true}

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=5 orderedList=false} -->

<!-- code_chunk_output -->

- [目標](#目標)
- [本題](#本題)
  - [応用数学](#応用数学)
    - [線形代数](#線形代数)
      - [行列](#行列)
      - [計算方法（２×２の正方行列の場合）](#計算方法22の正方行列の場合)
      - [単位行列と逆行列](#単位行列と逆行列)
      - [行列式](#行列式)
      - [固有値・固有ベクトル](#固有値固有ベクトル)
      - [固有値分解](#固有値分解)
      - [特異値・特異ベクトル](#特異値特異ベクトル)
    - [統計学](#統計学)
      - [集合](#集合)
      - [確率](#確率)
      - [統計](#統計)
    - [情報科学](#情報科学)
  - [機械学習](#機械学習)
    - [線形回帰モデル](#線形回帰モデル)
    - [非線形回帰モデル](#非線形回帰モデル)
    - [ロジスティック回帰モデル](#ロジスティック回帰モデル)
    - [主成分分析](#主成分分析)
    - [アルゴリズム（k 近傍法、k-means）](#アルゴリズムk-近傍法-k-means)
    - [サポートベクターマシン（SVM）](#サポートベクターマシンsvm)
  - [深層学習](#深層学習)
    - [入力層〜中間層](#入力層中間層)
    - [活性化関数](#活性化関数)
    - [出力層](#出力層)
    - [勾配降下法](#勾配降下法)
    - [誤差逆伝播法](#誤差逆伝播法)

<!-- /code_chunk_output -->

## 目標

E 資格の学習項目のまとめ

## 本題

###　応用数学

#### 線形代数

##### 行列

###### 行列

**行列** ： 記号や実数・複素数などの要素を、縦方向と横方向に長方形状（正方形も含む）に並べたもの。

用途は主に次の２つ

- ベクトルの変換
- 連立方程式を解く

横方向を **行**  
縦方向を **列** という。

![行列](../images/行列.png "行列")

##### 計算方法（２×２の正方行列の場合）

![行列の足し算](../images/行列の計算.png "行列の足し算")

##### 単位行列と逆行列

対角要素がすべて 1 でそのほかの要素がすべて 0 である正方行列のことを **単位行列** という。

![単位行列](../images/単位行列.png "単位行列")

行列 A について AX=XA=I となる行列 Y を A の逆行列といい、A<sup>-1</sup>で表す。

![逆行列](../images/逆行列.png "逆行列")

##### 行列式

行列式とは正方行列に対して決まるスカラーをいう。

![行列式](../images/行列式.png "行列式")

行列が大きくなった際の行列式は余因子展開などで求められる。

![余因子展開](../images/余因子展開.png "余因子展開")

取り出した成分の行番号と列番号の和で符号が反転するので注意

* 偶数の時→プラス

* 奇数の時→マイナス

行列式の重要な点は以下のこと。

__det(A)=0のとき,行列Aに逆行列は存在しない。__

##### 固有値・固有ベクトル

ｎ次正方行列Aに対して

![固有値・固有ベクトル](../images/固有値・固有ベクトル.png "固有値・固有ベクトル")

となるような定数λとベクトルx（ｎ次元の列ベクトル）が存在するとき，  
λをAの __固有値__ といい  
xをλに属する（に対する） __固有ベクトル__ という．

###### 求め方

![固有方程式](../images/固有方程式.png "固有方程式")

参考

[固有値，固有ベクトルの求め方](https://www.geisya.or.jp/~mwm48961/linear_algebra/eigenvalue2.htm)

###### 何に使うの？？
機械学習の主成分分析などに使用する。

#####　固有値分解
固有値・固有ベクトルの発展として固有値分解がある。

![固有値分解](../images/固有値分解.png "固有値分解")

このような分解を行うことで、行列の累乗計算が楽になる。

##### 特異値・特異ベクトル
正方行列でしか固有値分解はできないが、似たことはできる。  
それを特異値分解（SVD）という。
主に次元削減に使用される。

###### 求め方
![特異値分解](../images/特異値分解.png "特異値分解")

#### 統計学

##### 集合

##### 確率

##### 統計

#### 情報科学

### 機械学習

#### 線形回帰モデル

#### 非線形回帰モデル

#### ロジスティック回帰モデル

#### 主成分分析

#### アルゴリズム（k 近傍法、k-means）

#### サポートベクターマシン（SVM）

### 深層学習

#### 入力層〜中間層

#### 活性化関数

#### 出力層

#### 勾配降下法

#### 誤差逆伝播法
